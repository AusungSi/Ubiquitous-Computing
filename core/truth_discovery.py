# core/truth_discovery.py
import numpy as np
from config import KL_SENSITIVITY

class TruthDiscovery:
    """
    å®ç°åŸºäº KL æ•£åº¦çš„è·¨æ¨¡æ€çœŸå€¼å‘ç°
    å¯¹åº”æ–‡æ¡£ï¼š2.2 å¤šæºå¼‚æ„æ•°æ®çš„çœŸå€¼å‘ç°
    """
    def __init__(self, sensitivity=KL_SENSITIVITY):
        self.lambda_param = sensitivity
        self.states = ["Normal", "Risk", "Fall"] # çŠ¶æ€ç©ºé—´

    def _sensor_to_prob(self, hr_val):
        """
        å°†è¿ç»­ä¼ æ„Ÿå™¨æ•°å€¼æ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒ P(x)
        é€»è¾‘ï¼šåˆ©ç”¨é«˜æ–¯åˆ†å¸ƒæ€æƒ³ï¼Œåç¦»æ­£å¸¸å€¼è¶Šè¿œï¼Œé£é™©æ¦‚ç‡è¶Šé«˜
        """
        if 60 <= hr_val <= 100:
            return np.array([0.90, 0.08, 0.02]) # æ­£å¸¸
        elif 50 < hr_val < 60 or 100 < hr_val < 120:
            return np.array([0.30, 0.60, 0.10]) # äºšå¥åº·
        else:
            return np.array([0.05, 0.35, 0.60]) # æåº¦å±é™©/è·Œå€’å€¾å‘

    def _crowd_to_prob(self, labels):
        """
        å°†ç¦»æ•£æ–‡æœ¬æ ‡ç­¾æ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒ Q(x)
        """
        counts = {s: 0 for s in self.states}
        for l in labels:
            if l in counts: counts[l] += 1
        
        # æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘
        raw = np.array([counts[s] + 0.1 for s in self.states])
        return raw / np.sum(raw)

    def compute_trust_score(self, sensor_val, crowd_labels):
        """
        [æ—§æ¥å£] ä½¿ç”¨æ ‡ç­¾åˆ—è¡¨è®¡ç®—
        """
        P = self._sensor_to_prob(sensor_val)
        Q = self._crowd_to_prob(crowd_labels)
        
        epsilon = 1e-9
        kl_value = np.sum(P * np.log((P + epsilon) / (Q + epsilon)))
        confidence = 1.0 / (1.0 + self.lambda_param * kl_value)
        
        return confidence, kl_value

    # ==========================================
    # ğŸ‘‡ å¿…é¡»è¡¥ä¸Šè¿™ä¸ªæ–°æ–¹æ³• ğŸ‘‡
    # ==========================================
    def compute_trust_with_distribution(self, sensor_val, Q_distribution):
        """
        [æ–°æ¥å£] ç›´æ¥ä½¿ç”¨ BERT/NLP è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒ Q è®¡ç®— KL æ•£åº¦
        """
        # 1. è·å–ä¼ æ„Ÿå™¨åˆ†å¸ƒ P
        P = self._sensor_to_prob(sensor_val)
        
        # 2. è·å–ä¼ å…¥çš„ NLP åˆ†å¸ƒ Q
        Q = Q_distribution
        
        # 3. è®¡ç®— KL æ•£åº¦
        epsilon = 1e-9
        kl_value = np.sum(P * np.log((P + epsilon) / (Q + epsilon)))
        
        # 4. è®¡ç®—ç½®ä¿¡åº¦
        confidence = 1.0 / (1.0 + self.lambda_param * kl_value)
        
        return confidence, kl_value